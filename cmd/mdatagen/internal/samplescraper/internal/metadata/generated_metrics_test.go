// Code generated by mdatagen. DO NOT EDIT.

package metadata

import (
	"testing"

	"github.com/stretchr/testify/assert"
	"go.uber.org/zap"
	"go.uber.org/zap/zaptest/observer"

	"go.opentelemetry.io/collector/pdata/pcommon"
	"go.opentelemetry.io/collector/pdata/pmetric"
	"go.opentelemetry.io/collector/scraper/scrapertest"
)

type testDataSet int

const (
	testDataSetDefault testDataSet = iota
	testDataSetAll
	testDataSetNone
	testDataSetReag
)

func TestMetricsBuilder(t *testing.T) {
	tests := []struct {
		name        string
		metricsSet  testDataSet
		resAttrsSet testDataSet
		expectEmpty bool
	}{
		{
			name: "default",
		},
		{
			name:        "all_set",
			metricsSet:  testDataSetAll,
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "reaggregate_set",
			metricsSet:  testDataSetReag,
			resAttrsSet: testDataSetReag,
		},
		{
			name:        "none_set",
			metricsSet:  testDataSetNone,
			resAttrsSet: testDataSetNone,
			expectEmpty: true,
		},
		{
			name:        "filter_set_include",
			resAttrsSet: testDataSetAll,
		},
		{
			name:        "filter_set_exclude",
			resAttrsSet: testDataSetAll,
			expectEmpty: true,
		},
	}
	for _, tt := range tests {
		t.Run(tt.name, func(t *testing.T) {
			start := pcommon.Timestamp(1_000_000_000)
			ts := pcommon.Timestamp(1_000_001_000)
			observedZapCore, observedLogs := observer.New(zap.WarnLevel)
			settings := scrapertest.NewNopSettings(scrapertest.NopType)
			settings.Logger = zap.New(observedZapCore)
			mb := NewMetricsBuilder(loadMetricsBuilderConfig(t, tt.name), settings, WithStartTime(start))
			aggMap := make(map[string]string) // contains the aggregation strategies for each metric name
			aggMap["DefaultMetric"] = mb.metricDefaultMetric.config.AggregationStrategy
			aggMap["DefaultMetricToBeRemoved"] = mb.metricDefaultMetricToBeRemoved.config.AggregationStrategy
			aggMap["MetricInputType"] = mb.metricMetricInputType.config.AggregationStrategy
			aggMap["OptionalMetric"] = mb.metricOptionalMetric.config.AggregationStrategy
			aggMap["OptionalMetricEmptyUnit"] = mb.metricOptionalMetricEmptyUnit.config.AggregationStrategy
			aggMap["ReaggregateMetric"] = mb.metricReaggregateMetric.config.AggregationStrategy
			aggMap["SystemCPUTime"] = mb.metricSystemCPUTime.config.AggregationStrategy

			expectedWarnings := 0
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, "[WARNING] Please set `enabled` field explicitly for `default.metric`: This metric will be disabled by default soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.metricsSet == testDataSetDefault || tt.metricsSet == testDataSetAll {
				assert.Equal(t, "[WARNING] `default.metric.to_be_removed` should not be enabled: This metric is deprecated and will be removed soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.metricsSet == testDataSetAll || tt.metricsSet == testDataSetNone {
				assert.Equal(t, "[WARNING] `optional.metric` should not be configured: This metric is deprecated and will be removed soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.metricsSet == testDataSetAll || tt.metricsSet == testDataSetNone {
				assert.Equal(t, "[WARNING] `optional.metric.empty_unit` should not be configured: This metric is deprecated and will be removed soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.resAttrsSet == testDataSetDefault {
				assert.Equal(t, "[WARNING] Please set `enabled` field explicitly for `string.resource.attr_disable_warning`: This resource_attribute will be disabled by default soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.resAttrsSet == testDataSetAll || tt.resAttrsSet == testDataSetNone {
				assert.Equal(t, "[WARNING] `string.resource.attr_remove_warning` should not be configured: This resource_attribute is deprecated and will be removed soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.resAttrsSet == testDataSetDefault || tt.resAttrsSet == testDataSetAll {
				assert.Equal(t, "[WARNING] `string.resource.attr_to_be_removed` should not be enabled: This resource_attribute is deprecated and will be removed soon.", observedLogs.All()[expectedWarnings].Message)
				expectedWarnings++
			}
			if tt.metricsSet != testDataSetReag {
				assert.Equal(t, expectedWarnings, observedLogs.Len())
			}

			defaultMetricsCount := 0
			allMetricsCount := 0

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordDefaultMetricDataPoint(ts, 1, "string_attr-val", 19, AttributeEnumAttrRed, []any{"slice_attr-item1", "slice_attr-item2"}, map[string]any{"key1": "map_attr-val1", "key2": "map_attr-val2"})
			if tt.name == "reaggregate_set" {
				mb.RecordDefaultMetricDataPoint(ts, 3, "string_attr-val-2", 20, AttributeEnumAttrGreen, []any{"slice_attr-item3", "slice_attr-item4"}, map[string]any{"key3": "map_attr-val3", "key4": "map_attr-val4"})
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordDefaultMetricToBeRemovedDataPoint(ts, 1)
			if tt.name == "reaggregate_set" {
				mb.RecordDefaultMetricToBeRemovedDataPoint(ts, 3)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordMetricInputTypeDataPoint(ts, "1", "string_attr-val", 19, AttributeEnumAttrRed, []any{"slice_attr-item1", "slice_attr-item2"}, map[string]any{"key1": "map_attr-val1", "key2": "map_attr-val2"})
			if tt.name == "reaggregate_set" {
				mb.RecordMetricInputTypeDataPoint(ts, "3", "string_attr-val-2", 20, AttributeEnumAttrGreen, []any{"slice_attr-item3", "slice_attr-item4"}, map[string]any{"key3": "map_attr-val3", "key4": "map_attr-val4"})
			}

			allMetricsCount++
			mb.RecordOptionalMetricDataPoint(ts, 1, "string_attr-val", true, false)
			if tt.name == "reaggregate_set" {
				mb.RecordOptionalMetricDataPoint(ts, 3, "string_attr-val-2", false, true)
			}

			allMetricsCount++
			mb.RecordOptionalMetricEmptyUnitDataPoint(ts, 1, "string_attr-val", true)
			if tt.name == "reaggregate_set" {
				mb.RecordOptionalMetricEmptyUnitDataPoint(ts, 3, "string_attr-val-2", false)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordReaggregateMetricDataPoint(ts, 1, "string_attr-val", true)
			if tt.name == "reaggregate_set" {
				mb.RecordReaggregateMetricDataPoint(ts, 3, "string_attr-val-2", false)
			}

			defaultMetricsCount++
			allMetricsCount++
			mb.RecordSystemCPUTimeDataPoint(ts, 1)
			if tt.name == "reaggregate_set" {
				mb.RecordSystemCPUTimeDataPoint(ts, 3)
			}

			rb := mb.NewResourceBuilder()
			rb.SetMapResourceAttr(map[string]any{"key1": "map.resource.attr-val1", "key2": "map.resource.attr-val2"})
			rb.SetOptionalResourceAttr("optional.resource.attr-val")
			rb.SetSliceResourceAttr([]any{"slice.resource.attr-item1", "slice.resource.attr-item2"})
			rb.SetStringEnumResourceAttrOne()
			rb.SetStringResourceAttr("string.resource.attr-val")
			rb.SetStringResourceAttrDisableWarning("string.resource.attr_disable_warning-val")
			rb.SetStringResourceAttrRemoveWarning("string.resource.attr_remove_warning-val")
			rb.SetStringResourceAttrToBeRemoved("string.resource.attr_to_be_removed-val")
			res := rb.Emit()
			metrics := mb.Emit(WithResource(res))
			if tt.name == "reaggregate_set" {
				assert.Empty(t, mb.metricDefaultMetric.aggDataPoints)
				assert.Empty(t, mb.metricDefaultMetricToBeRemoved.aggDataPoints)
				assert.Empty(t, mb.metricMetricInputType.aggDataPoints)
				assert.Empty(t, mb.metricOptionalMetric.aggDataPoints)
				assert.Empty(t, mb.metricOptionalMetricEmptyUnit.aggDataPoints)
				assert.Empty(t, mb.metricReaggregateMetric.aggDataPoints)
				assert.Empty(t, mb.metricSystemCPUTime.aggDataPoints)
			}

			if tt.expectEmpty {
				assert.Equal(t, 0, metrics.ResourceMetrics().Len())
				return
			}

			assert.Equal(t, 1, metrics.ResourceMetrics().Len())
			rm := metrics.ResourceMetrics().At(0)
			assert.Equal(t, res, rm.Resource())
			assert.Equal(t, 1, rm.ScopeMetrics().Len())
			ms := rm.ScopeMetrics().At(0).Metrics()
			if tt.metricsSet == testDataSetDefault {
				assert.Equal(t, defaultMetricsCount, ms.Len())
			}
			if tt.metricsSet == testDataSetAll {
				assert.Equal(t, allMetricsCount, ms.Len())
			}
			validatedMetrics := make(map[string]bool)
			for i := 0; i < ms.Len(); i++ {
				switch ms.At(i).Name() {
				case "default.metric":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["default.metric"], "Found a duplicate in the metrics slice: default.metric")
						validatedMetrics["default.metric"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Monotonic cumulative sum int metric enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
						attrVal, ok := dp.Attributes().Get("string_attr")
						assert.True(t, ok)
						assert.Equal(t, "string_attr-val", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("state")
						assert.True(t, ok)
						assert.EqualValues(t, 19, attrVal.Int())
						attrVal, ok = dp.Attributes().Get("enum_attr")
						assert.True(t, ok)
						assert.Equal(t, "red", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("slice_attr")
						assert.True(t, ok)
						assert.Equal(t, []any{"slice_attr-item1", "slice_attr-item2"}, attrVal.Slice().AsRaw())
						attrVal, ok = dp.Attributes().Get("map_attr")
						assert.True(t, ok)
						assert.Equal(t, map[string]any{"key1": "map_attr-val1", "key2": "map_attr-val2"}, attrVal.Map().AsRaw())
					} else {
						assert.False(t, validatedMetrics["default.metric"], "Found a duplicate in the metrics slice: default.metric")
						validatedMetrics["default.metric"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Monotonic cumulative sum int metric enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["default.metric"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
						_, ok := dp.Attributes().Get("string_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("state")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("enum_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("slice_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("map_attr")
						assert.False(t, ok)
					}
				case "default.metric.to_be_removed":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["default.metric.to_be_removed"], "Found a duplicate in the metrics slice: default.metric.to_be_removed")
						validatedMetrics["default.metric.to_be_removed"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "[DEPRECATED] Non-monotonic delta sum double metric enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityDelta, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
					} else {
						assert.False(t, validatedMetrics["default.metric.to_be_removed"], "Found a duplicate in the metrics slice: default.metric.to_be_removed")
						validatedMetrics["default.metric.to_be_removed"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "[DEPRECATED] Non-monotonic delta sum double metric enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.False(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityDelta, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["default.metric.to_be_removed"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
					}
				case "metric.input_type":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["metric.input_type"], "Found a duplicate in the metrics slice: metric.input_type")
						validatedMetrics["metric.input_type"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Monotonic cumulative sum int metric with string input_type enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
						attrVal, ok := dp.Attributes().Get("string_attr")
						assert.True(t, ok)
						assert.Equal(t, "string_attr-val", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("state")
						assert.True(t, ok)
						assert.EqualValues(t, 19, attrVal.Int())
						attrVal, ok = dp.Attributes().Get("enum_attr")
						assert.True(t, ok)
						assert.Equal(t, "red", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("slice_attr")
						assert.True(t, ok)
						assert.Equal(t, []any{"slice_attr-item1", "slice_attr-item2"}, attrVal.Slice().AsRaw())
						attrVal, ok = dp.Attributes().Get("map_attr")
						assert.True(t, ok)
						assert.Equal(t, map[string]any{"key1": "map_attr-val1", "key2": "map_attr-val2"}, attrVal.Map().AsRaw())
					} else {
						assert.False(t, validatedMetrics["metric.input_type"], "Found a duplicate in the metrics slice: metric.input_type")
						validatedMetrics["metric.input_type"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Monotonic cumulative sum int metric with string input_type enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["metric.input_type"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
						_, ok := dp.Attributes().Get("string_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("state")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("enum_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("slice_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("map_attr")
						assert.False(t, ok)
					}
				case "optional.metric":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["optional.metric"], "Found a duplicate in the metrics slice: optional.metric")
						validatedMetrics["optional.metric"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "[DEPRECATED] Gauge double metric disabled by default.", ms.At(i).Description())
						assert.Equal(t, "1", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						attrVal, ok := dp.Attributes().Get("string_attr")
						assert.True(t, ok)
						assert.Equal(t, "string_attr-val", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("boolean_attr")
						assert.True(t, ok)
						assert.True(t, attrVal.Bool())
						attrVal, ok = dp.Attributes().Get("boolean_attr2")
						assert.True(t, ok)
						assert.False(t, attrVal.Bool())
					} else {
						assert.False(t, validatedMetrics["optional.metric"], "Found a duplicate in the metrics slice: optional.metric")
						validatedMetrics["optional.metric"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "[DEPRECATED] Gauge double metric disabled by default.", ms.At(i).Description())
						assert.Equal(t, "1", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["optional.metric"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
						_, ok := dp.Attributes().Get("string_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("boolean_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("boolean_attr2")
						assert.False(t, ok)
					}
				case "optional.metric.empty_unit":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["optional.metric.empty_unit"], "Found a duplicate in the metrics slice: optional.metric.empty_unit")
						validatedMetrics["optional.metric.empty_unit"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "[DEPRECATED] Gauge double metric disabled by default.", ms.At(i).Description())
						assert.Empty(t, ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						attrVal, ok := dp.Attributes().Get("string_attr")
						assert.True(t, ok)
						assert.Equal(t, "string_attr-val", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("boolean_attr")
						assert.True(t, ok)
						assert.True(t, attrVal.Bool())
					} else {
						assert.False(t, validatedMetrics["optional.metric.empty_unit"], "Found a duplicate in the metrics slice: optional.metric.empty_unit")
						validatedMetrics["optional.metric.empty_unit"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "[DEPRECATED] Gauge double metric disabled by default.", ms.At(i).Description())
						assert.Empty(t, ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["optional.metric.empty_unit"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
						_, ok := dp.Attributes().Get("string_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("boolean_attr")
						assert.False(t, ok)
					}
				case "reaggregate.metric":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["reaggregate.metric"], "Found a duplicate in the metrics slice: reaggregate.metric")
						validatedMetrics["reaggregate.metric"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "Metric for testing spatial reaggregation", ms.At(i).Description())
						assert.Equal(t, "1", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						attrVal, ok := dp.Attributes().Get("string_attr")
						assert.True(t, ok)
						assert.Equal(t, "string_attr-val", attrVal.Str())
						attrVal, ok = dp.Attributes().Get("boolean_attr")
						assert.True(t, ok)
						assert.True(t, attrVal.Bool())
					} else {
						assert.False(t, validatedMetrics["reaggregate.metric"], "Found a duplicate in the metrics slice: reaggregate.metric")
						validatedMetrics["reaggregate.metric"] = true
						assert.Equal(t, pmetric.MetricTypeGauge, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Gauge().DataPoints().Len())
						assert.Equal(t, "Metric for testing spatial reaggregation", ms.At(i).Description())
						assert.Equal(t, "1", ms.At(i).Unit())
						dp := ms.At(i).Gauge().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeDouble, dp.ValueType())
						switch aggMap["reaggregate.metric"] {
						case "sum":
							assert.InDelta(t, float64(4), dp.DoubleValue(), 0.01)
						case "avg":
							assert.InDelta(t, float64(2), dp.DoubleValue(), 0.01)
						case "min":
							assert.InDelta(t, float64(1), dp.DoubleValue(), 0.01)
						case "max":
							assert.InDelta(t, float64(3), dp.DoubleValue(), 0.01)
						}
						_, ok := dp.Attributes().Get("string_attr")
						assert.False(t, ok)
						_, ok = dp.Attributes().Get("boolean_attr")
						assert.False(t, ok)
					}
				case "system.cpu.time":
					if tt.name != "reaggregate_set" {
						assert.False(t, validatedMetrics["system.cpu.time"], "Found a duplicate in the metrics slice: system.cpu.time")
						validatedMetrics["system.cpu.time"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Monotonic cumulative sum int metric enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						assert.Equal(t, int64(1), dp.IntValue())
					} else {
						assert.False(t, validatedMetrics["system.cpu.time"], "Found a duplicate in the metrics slice: system.cpu.time")
						validatedMetrics["system.cpu.time"] = true
						assert.Equal(t, pmetric.MetricTypeSum, ms.At(i).Type())
						assert.Equal(t, 1, ms.At(i).Sum().DataPoints().Len())
						assert.Equal(t, "Monotonic cumulative sum int metric enabled by default.", ms.At(i).Description())
						assert.Equal(t, "s", ms.At(i).Unit())
						assert.True(t, ms.At(i).Sum().IsMonotonic())
						assert.Equal(t, pmetric.AggregationTemporalityCumulative, ms.At(i).Sum().AggregationTemporality())
						dp := ms.At(i).Sum().DataPoints().At(0)
						assert.Equal(t, start, dp.StartTimestamp())
						assert.Equal(t, ts, dp.Timestamp())
						assert.Equal(t, pmetric.NumberDataPointValueTypeInt, dp.ValueType())
						switch aggMap["system.cpu.time"] {
						case "sum":
							assert.Equal(t, int64(4), dp.IntValue())
						case "avg":
							assert.Equal(t, int64(2), dp.IntValue())
						case "min":
							assert.Equal(t, int64(1), dp.IntValue())
						case "max":
							assert.Equal(t, int64(3), dp.IntValue())
						}
					}
				}
			}
		})
	}
}
